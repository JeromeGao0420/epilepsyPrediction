import torch
import torch.nn as nn

# --- 1. Squeeze-and-Excitation (SE) é€šé“æ³¨æ„åŠ›æ¨¡å— ---
# è¿™ä¸ªæ¨¡å—è´Ÿè´£è®¡ç®—æ¯ä¸ªç‰¹å¾é€šé“çš„é‡è¦æ€§ï¼Œç”¨äºå®šä½çš„å¯è§£é‡Šæ€§ã€‚
class SEBlock(nn.Module):
    def __init__(self, channel, reduction=8):
        """
        channel: è¾“å…¥ç‰¹å¾é€šé“æ•° (è¿™é‡Œæ˜¯ F1 * D)
        reduction: é™ç»´æ¯”ç‡ï¼Œå‡å°‘å‚æ•°é‡
        """
        super(SEBlock, self).__init__()
        # 1. Squeeze (æŒ¤å‹): å…¨å±€å¹³å‡æ± åŒ–ï¼Œå°† (B, C, H, W) å˜ä¸º (B, C, 1, 1)
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        
        # 2. Excitation (æ¿€åŠ±): ä¸¤ä¸ªå…¨è¿æ¥å±‚è®¡ç®—æƒé‡
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid() # æƒé‡åœ¨ 0 åˆ° 1 ä¹‹é—´
        )
        # ç”¨äºä¸´æ—¶å­˜å‚¨æ³¨æ„åŠ›æƒé‡ï¼Œæ–¹ä¾¿åç»­åœ¨ forward ä¸­è¿”å›
        self.attention_weights = None 

    def forward(self, x):
        b, c, _, _ = x.size()
        
        # æŒ¤å‹æ“ä½œï¼šä»ç©ºé—´ç»´åº¦èšåˆä¿¡æ¯
        y = self.avg_pool(x).view(b, c) 
        
        # æ¿€åŠ±æ“ä½œï¼šè®¡ç®—æ¯ä¸ªé€šé“çš„æƒé‡
        y = self.fc(y).view(b, c, 1, 1)
        
        # å­˜å‚¨æƒé‡ï¼Œç”¨äºå¯è§†åŒ–ã€‚æˆ‘ä»¬å°† y å‹ç¼©æˆ (B, C) çš„å½¢çŠ¶ä»¥ä¾¿å¤„ç†
        self.attention_weights = y.squeeze(-1).squeeze(-1)

        # ä¹˜å›åŸè¾“å…¥ï¼ŒåŠ å¼ºé‡è¦çš„é€šé“ï¼Œå‰Šå¼±ä¸é‡è¦çš„é€šé“
        return x * y.expand_as(x)


# --- 2. å¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶çš„ EEGNet æ¨¡å‹ ---
class EEGNet(nn.Module):
    def __init__(self, nb_classes, Chans=23, Samples=512, 
                 dropoutRate=0.5, kernLength=64, F1=8, D=2, F2=16, norm_rate=0.25, dropoutType='Dropout'):
        
        super(EEGNet, self).__init__()
        self.Chans = Chans
        self.Samples = Samples
        self.D = D
        self.F1 = F1

        # Block 1: Temporal Convolution
        self.conv1 = nn.Sequential(
            nn.Conv2d(1, F1, (1, kernLength), padding=(0, kernLength // 2), bias=False),
            nn.BatchNorm2d(F1)
        )

        # Block 2: Depthwise Convolution (Spatial Filtering)
        self.conv2_spatial = nn.Sequential(
            nn.Conv2d(F1, F1 * D, (Chans, 1), groups=F1, bias=False),
            nn.BatchNorm2d(F1 * D),
            nn.ELU(),
        )
        
        # ğŸ’¡ åˆ›æ–°ç‚¹ï¼šæ’å…¥é€šé“æ³¨æ„åŠ›æ¨¡å— ğŸ’¡
        # Attention channel count is F1 * D
        self.attention_module = SEBlock(channel=F1 * D, reduction=8)
        
        # Block 2 remainder
        self.conv2_pool_drop = nn.Sequential(
            nn.AvgPool2d((1, 4)),
            nn.Dropout(dropoutRate)
        )
        
        # Block 3: Separable Convolution
        self.conv3 = nn.Sequential(
            nn.Conv2d(F1 * D, F1 * D, (1, 16), padding=(0, 8), groups=F1 * D, bias=False),
            nn.Conv2d(F1 * D, F2, (1, 1), bias=False),
            nn.BatchNorm2d(F2),
            nn.ELU(),
            nn.AvgPool2d((1, 8)),
            nn.Dropout(dropoutRate)
        )

        # Classifier
        linear_in = F2 * (self.Samples // 32)
        self.linear = nn.Linear(linear_in, nb_classes)
        self.classifier = nn.Sequential(
            nn.Flatten(),
            self.linear
        )

    def forward(self, x):
        # 1. Block 1
        x = self.conv1(x)
        
        # 2. Block 2 Spatial Filtering
        x = self.conv2_spatial(x)
        
        # 3. ğŸ’¡ Attention Module ğŸ’¡
        # x_attended is the feature map enhanced by attention
        x_attended = self.attention_module(x)
        
        # 4. Block 2 Remainder
        x = self.conv2_pool_drop(x_attended)
        
        # 5. Block 3
        x = self.conv3(x)
        
        # 6. Classifier
        x = self.classifier(x)
        
        # 7. è¿”å›å€¼ä¿®æ”¹ï¼šåŒæ—¶è¿”å›åˆ†ç±»ç»“æœå’Œæ³¨æ„åŠ›æƒé‡
        # attention_weights å½¢çŠ¶æ˜¯ (Batch, F1*D)
        attention_map = self.attention_module.attention_weights 
        
        return x, attention_map 

# --- æµ‹è¯•ä»£ç  ---  
if __name__ == "__main__":  
    # å‡è®¾æˆ‘ä»¬æœ‰ Batch=32, 23ä¸ªé€šé“, 512ä¸ªæ—¶é—´ç‚¹  
    input_data = torch.randn(32, 1, 23, 512)  
    model = EEGNet(nb_classes=2, Chans=23, Samples=512)  
    output, attention_map = model(input_data)  
    
    # é¢„æœŸå½¢çŠ¶: output [32, 2], attention_map [32, F1*D] (ä¾‹å¦‚ [32, 16])
    print("æ¨¡å‹è¾“å‡ºå½¢çŠ¶:", output.shape) 
    print("æ³¨æ„åŠ›å›¾å½¢çŠ¶:", attention_map.shape) 
    print("Attention-EEGNet æ¨¡å‹æ„å»ºæˆåŠŸï¼")